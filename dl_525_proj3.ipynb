{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COSC 525 - Deep Learning\n",
    "Project #3: Building Networks with Tensorflow and Keras\n",
    "Contributors: Anna-Maria Nau and Christoph Metzner\n",
    "Date: 03/10/20\n",
    "\"\"\"\n",
    "# Import main libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Import other libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Fashion-Mnist Dataset from Keras and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fashion-mnist dataset from\n",
    "# https://keras.io/datasets/#fashion-mnist-database-of-fashion-articles\n",
    "# Downloads the data, will take some time so make yourself some tea!\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# Change format of label dataset --> from 1 to [0,1,0,0,0,0,0,0,0,0]\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "# from https://www.tensorflow.org/tutorials/keras/classification\n",
    "# creat list with all respective class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get min, and max value from training data set using all 60,000 samples\n",
    "max_val = x_train.max()\n",
    "print(\"Maximal value: \", max_val)\n",
    "min_val = x_train.min()\n",
    "print(\"Minimum value: \", min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init a normalization funciton\n",
    "def normalization(matrix, max_val, min_val):\n",
    "    new_matrix = np.array([((image - min_val)/(max_val-min_val)) for image in matrix])\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training (x_train) and testing (x_test) datasets based on maximal and minimal values of the training dataset\n",
    "x_train_scaled = normalization(x_train, max_val, min_val)\n",
    "x_test_scaled = normalization(x_test, max_val, min_val)\n",
    "\n",
    "# Show normalized image matrix and original matrix\n",
    "print(x_train_scaled[10])\n",
    "print(x_train[10])\n",
    "print(x_train.shape)\n",
    "print(x_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_x_train_scaled = np.reshape(x_train_scaled,(60000,28,28,1))\n",
    "reshaped_x_test_scaled = np.reshape(x_test_scaled,(10000,28,28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.tensorflow.org/tutorials/keras/classification\n",
    "\n",
    "# Plot first image of the training dataset\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "##########\n",
    "\n",
    "# Plot the first images plus their labels \n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "# Class which enables to store the execution time per epoch\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_time(time_stamps):\n",
    "   # accumulate all single time values\n",
    "    accumulated_time = []\n",
    "    acc_time = 0\n",
    "    for time in time_stamps:\n",
    "        acc_time += time\n",
    "        accumulated_time.append(acc_time)\n",
    "    #print(accumulated_time)   \n",
    "    return accumulated_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, x_train, y_train, x_test, y_test, class_names):\n",
    "    print(model.summary())\n",
    "    print()\n",
    "    # compile the given model architecture\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # call class for taking time stamps for each epoch\n",
    "    time_callback_train = TimeHistory()\n",
    "    \n",
    "    # fit the model (train the network) and save metrics in variable history\n",
    "    history = model.fit(x_train, y_train, epochs=50, batch_size=200, callbacks=[time_callback_train])\n",
    "    \n",
    "    # store time stamps per epoch in variable\n",
    "    times_train = small_cnn_time_callback_train.times\n",
    "    print()\n",
    "    print(\"Reported times per epoch: \\n \", times_train)\n",
    "    \n",
    "    accumulated_time = acc_time(times_train)\n",
    "    \n",
    "    # Evaluate model using testing dataset\n",
    "    test_start_time = time.time()\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=200, verbose=2)\n",
    "    print()\n",
    "    print()\n",
    "    print('Test Loss: {} and Test Accuracy: {}'.format(test_loss, test_acc))\n",
    "    test_end_time = time.time() - test_start_time\n",
    "    print('Time for Testing Data: ', test_end_time)\n",
    "    \n",
    "    \n",
    "    # show plots\n",
    "    # Plot training accuracy values vs epochs\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('Model accuracy vs Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training loss values vs epochs\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Model loss vs Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training time vs epochs\n",
    "    plt.plot(accumulated_time, history.history['loss'])\n",
    "    plt.title('Model Loss vs Time')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Time in seconds')\n",
    "    plt.legend(['Train'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(model, x_test, y_test):\n",
    "    # Generate prediction output from model using scaled testing dataset\n",
    "    # Using keras predict_classes\n",
    "    predictions = model.predict_classes(x_test, verbose=2)\n",
    "\n",
    "    # Creating the confusion matrix using sklearn library\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    # Changing confusing matrix output using pandas library\n",
    "    conf_matrix = pd.DataFrame(conf_matrix)\n",
    "    conf_matrix\n",
    "    # Changing index / columns names to class names of output\n",
    "    conf_matrix.columns = class_names\n",
    "    conf_matrix.index = class_names\n",
    "    \n",
    "    return(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "FC_model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28), name=\"FC_Input_Layer\"),\n",
    "    keras.layers.Dense(784, activation='tanh', name=\"FC_Hidden_Layer_1\"),\n",
    "    keras.layers.Dense(512, activation='sigmoid',name=\"FC_Hidden_Layer_2\"),\n",
    "    keras.layers.Dense(100, activation='relu', name=\"FC_Hidden_Layer_3\"),\n",
    "    keras.layers.Dense(10, activation='softmax', name=\"FC_Output_Layer\")],\n",
    "    name='Fully_Connected_NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Small Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Small_CNN = Sequential()\n",
    "Small_CNN.add(layers.Conv2D(filters=40, kernel_size=(5,5),strides=5,padding='valid', activation='relu', input_shape=(28, 28, 1)))\n",
    "Small_CNN.add(layers.MaxPooling2D((2, 2)))\n",
    "Small_CNN.add(layers.Flatten())\n",
    "Small_CNN.add(layers.Dense(100, activation='relu'))\n",
    "Small_CNN.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Bigger Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built the CNN architecture\n",
    "bigger_CNN = Sequential(name='Bigger_CNN')\n",
    "bigger_CNN.add(layers.Conv2D(filters=48, kernel_size=(3,3),strides=1,padding='valid',activation='relu',input_shape=(28,28,1)))\n",
    "bigger_CNN.add(layers.MaxPooling2D((2,2,)))\n",
    "bigger_CNN.add(layers.Conv2D(filters=96, kernel_size=(3,3), strides=1, padding='valid', activation='relu'))\n",
    "bigger_CNN.add(layers.MaxPooling2D((2,2,)))\n",
    "bigger_CNN.add(layers.Flatten())\n",
    "bigger_CNN.add(layers.Dense(100, activation='relu'))\n",
    "bigger_CNN.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Task 1: Fully Connected Network\n",
    "run_model(FC_model, x_train_scaled, y_train_cat, x_test_scaled, y_test_cat, class_names)\n",
    "conf_mat(FC_model, x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 2: Small CNN\n",
    "run_model(small_cnn, reshaped_x_train_scaled, y_train_cat, reshaped_x_test_scaled, y_test_cat, class_names)\n",
    "conf_mat(small_cnn, reshaped_x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Bigger CNN\n",
    "run_model(bigger_CNN, reshaped_x_train_scaled, y_train_cat, reshaped_x_test_scaled, y_test_cat, class_names)\n",
    "conf_mat(bigger_CNN, reshaped_x_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
